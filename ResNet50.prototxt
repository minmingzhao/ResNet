# Enter your network definition here.
# Use Shift+Enter to update the visualization.
# http://ethereon.github.io/netscope/#/editor
name: "ResNet-50"
input: "data"
input_dim: 1
input_dim: 3
input_dim: 500
input_dim: 500

layer {
	bottom: "data"
	top: "conv1"
	name: "C1: h1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 7
		pad: 3
		stride: 2
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "C1: bn1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "conv1"
	top: "conv1"
	name: "C1: relu1"
	type: "ReLU"
}

layer {
	bottom: "conv1"
	top: "pool1"
	name: "C1: pool1"
	type: "Pooling"
	pooling_param {
		kernel_size: 3
		stride: 2
		pool: MAX
	}
}

layer {
	bottom: "pool1"
	top: "res2a_branch1"
	name: "C2_1: h_proj2"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch1"
	top: "res2a_branch1"
	name: "C2_1: bn_proj2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "pool1"
	top: "res2a_branch2a"
	name: "C2_1: h2a_1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2a"
	name: "C2_1: bn2a_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2a"
	name: "c2_1: relu2a_1"
	type: "ReLU"
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2b"
	name: "C2_1: h2b_1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2b"
	name: "C2_1: bn2b_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2b"
	name: "C2_1: relu2b_1"
	type: "ReLU"
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2c"
	name: "C2_1: h2c_1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2c"
	top: "res2a_branch2c"
	name: "C2_1: bn2c_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res2a_branch1"
	bottom: "res2a_branch2c"
	top: "res2a"
	name: "C2_1: add2_1"
	type: "Eltwise"
}

layer {
	bottom: "res2a"
	top: "res2a"
	name: "C2_1: relu2_1"
	type: "ReLU"
}

layer {
	bottom: "res2a"
	top: "res2b_branch2a"
	name: "C2_2: h2a_2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2a"
	name: "C2_2: bn2a_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2a"
	name: "C2_2: relu2a_2"
	type: "ReLU"
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2b"
	name: "C2_2: h2b_2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2b"
	name: "C2_2: bn2b_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2b"
	name: "C2_2: relu2b_2"
	type: "ReLU"
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2c"
	name: "C2_2: h2c_2"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2c"
	top: "res2b_branch2c"
	name: "C2_2: bn2c_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res2a"
	bottom: "res2b_branch2c"
	top: "res2b"
	name: "C2_2: add2_2"
	type: "Eltwise"
}

layer {
	bottom: "res2b"
	top: "res2b"
	name: "C2_2: relu2_2"
	type: "ReLU"
}

layer {
	bottom: "res2b"
	top: "res2c_branch2a"
	name: "C2_3: h2a_3"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2a"
	name: "C2_3: bn2a_3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2a"
	name: "C2_3: relu2a_3"
	type: "ReLU"
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2b"
	name: "C2_3: h2b_3"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2b"
	name: "C2_3: bn2b_3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2b"
	name: "C2_3: relu2b_3"
	type: "ReLU"
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2c"
	name: "C2_3: h2c_3"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2c"
	top: "res2c_branch2c"
	name: "C2_3: bn2c_3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res2b"
	bottom: "res2c_branch2c"
	top: "res2c"
	name: "C2_3: add2_3"
	type: "Eltwise"
}

layer {
	bottom: "res2c"
	top: "res2c"
	name: "C2_3: relu2_3"
	type: "ReLU"
}

layer {
	bottom: "res2c"
	top: "res3a_branch1"
	name: "C3_1: h_proj3"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch1"
	top: "res3a_branch1"
	name: "C3_1: bn_proj3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res2c"
	top: "res3a_branch2a"
	name: "C3_1: h3a_1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2a"
	name: "C3_1: bn3a_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2a"
	name: "C3_1: relu3a_1"
	type: "ReLU"
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2b"
	name: "C3_1: h3b_1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2b"
	name: "C3_1: bn3b_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2b"
	name: "C3_1: relu3b_1"
	type: "ReLU"
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2c"
	name: "C3_1: h3c_1"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2c"
	top: "res3a_branch2c"
	name: "C3_1: bn3c_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res3a_branch1"
	bottom: "res3a_branch2c"
	top: "res3a"
	name: "C3_1: add3_1"
	type: "Eltwise"
}

layer {
	bottom: "res3a"
	top: "res3a"
	name: "C3_1: relu3_1"
	type: "ReLU"
}


layer {
	bottom: "res3a"
	top: "res3b_branch2a"
	name: "C3_2: h3a_2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b_branch2a"
	top: "res3b_branch2a"
	name: "C3_2: bn3a_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res3b_branch2a"
	top: "res3b_branch2a"
	name: "C3_2: relu3a_2"
	type: "ReLU"
}

layer {
	bottom: "res3b_branch2a"
	top: "res3b_branch2b"
	name: "C3_2: h3b_2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b_branch2b"
	top: "res3b_branch2b"
	name: "C3_2: bn3b_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res3b_branch2b"
	top: "res3b_branch2b"
	name: "C3_2: relu3b_2"
	type: "ReLU"
}

layer {
	bottom: "res3b_branch2b"
	top: "res3b_branch2c"
	name: "C3_2: h3c_2"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b_branch2c"
	top: "res3b_branch2c"
	name: "C3_2: bn3c_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res3a"
	bottom: "res3b_branch2c"
	top: "res3b"
	name: "C3_2: add3_2"
	type: "Eltwise"
}

layer {
	bottom: "res3b"
	top: "res3b"
	name: "C3_2: relu3_2"
	type: "ReLU"
}

layer {
	bottom: "res3b"
	top: "res3c_branch2a"
	name: "C3_3: h3a_3"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3c_branch2a"
	top: "res3c_branch2a"
	name: "C3_3: bn3a_3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res3c_branch2a"
	top: "res3c_branch2a"
	name: "C3_3: relu3a_3"
	type: "ReLU"
}

layer {
	bottom: "res3c_branch2a"
	top: "res3c_branch2b"
	name: "C3_3: h3b_3"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3c_branch2b"
	top: "res3c_branch2b"
	name: "C3_3: bn3b_3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res3c_branch2b"
	top: "res3c_branch2b"
	name: "C3_3: relu3b_3"
	type: "ReLU"
}

layer {
	bottom: "res3c_branch2b"
	top: "res3c_branch2c"
	name: "C3_3: h3c_3"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3c_branch2c"
	top: "res3c_branch2c"
	name: "C3_3: bn3c_3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res3b"
	bottom: "res3c_branch2c"
	top: "res3c"
	name: "C3_3: add3_3"
	type: "Eltwise"
}

layer {
	bottom: "res3c"
	top: "res3c"
	name: "C3_3: relu3_3"
	type: "ReLU"
}

layer {
	bottom: "res3c"
	top: "res3d_branch2a"
	name: "C3_4: h3a_4"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3d_branch2a"
	top: "res3d_branch2a"
	name: "C3_4: bn3a_4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res3d_branch2a"
	top: "res3d_branch2a"
	name: "C3_4: relu3a_4"
	type: "ReLU"
}

layer {
	bottom: "res3d_branch2a"
	top: "res3d_branch2b"
	name: "C3_4: h3b_4"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3d_branch2b"
	top: "res3d_branch2b"
	name: "C3_4: bn3b_4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res3d_branch2b"
	top: "res3d_branch2b"
	name: "C3_4: relu3b_4"
	type: "ReLU"
}

layer {
	bottom: "res3d_branch2b"
	top: "res3d_branch2c"
	name: "C3_4: h3c_4"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3d_branch2c"
	top: "res3d_branch2c"
	name: "C3_4: bn3c_4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res3c"
	bottom: "res3d_branch2c"
	top: "res3d"
	name: "C3_4: add3_4"
	type: "Eltwise"
}

layer {
	bottom: "res3d"
	top: "res3d"
	name: "C3_4: relu3_4"
	type: "ReLU"
}

layer {
	bottom: "res3d"
	top: "res4a_branch1"
	name: "C4_1: h_proj4"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch1"
	top: "res4a_branch1"
	name: "C4_1: bn_proj4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res3d"
	top: "res4a_branch2a"
	name: "C4_1: h4a_1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2a"
	name: "C4_1: bn4a_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2a"
	name: "C4_1: relu4a_1"
	type: "ReLU"
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2b"
	name: "C4_1: h4b_1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2b"
	name: "C4_1: bn4b_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2b"
	name: "C4_1: relu4b_1"
	type: "ReLU"
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2c"
	name: "C4_1: h4c_1"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2c"
	top: "res4a_branch2c"
	name: "C4_1: bn4c_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4a_branch1"
	bottom: "res4a_branch2c"
	top: "res4a"
	name: "C4_1: add4_1"
	type: "Eltwise"
}

layer {
	bottom: "res4a"
	top: "res4a"
	name: "C4_1: relu4_1"
	type: "ReLU"
}

layer {
	bottom: "res4a"
	top: "res4b_branch2a"
	name: "C4_2: h4a_2"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b_branch2a"
	top: "res4b_branch2a"
	name: "C4_2: bn4a_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res4b_branch2a"
	top: "res4b_branch2a"
	name: "C4_2: relu4a_2"
	type: "ReLU"
}

layer {
	bottom: "res4b_branch2a"
	top: "res4b_branch2b"
	name: "C4_2: h4b_2"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b_branch2b"
	top: "res4b_branch2b"
	name: "C4_2: bn4b_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res4b_branch2b"
	top: "res4b_branch2b"
	name: "C4_2: relu4b_2"
	type: "ReLU"
}

layer {
	bottom: "res4b_branch2b"
	top: "res4b_branch2c"
	name: "C4_2: h4c_2"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b_branch2c"
	top: "res4b_branch2c"
	name: "C4_2: bn4c_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res4a"
	bottom: "res4b_branch2c"
	top: "res4b"
	name: "C4_2: add4_2"
	type: "Eltwise"
}

layer {
	bottom: "res4b"
	top: "res4b"
	name: "C4_2: relu4_2"
	type: "ReLU"
}

layer {
	bottom: "res4b"
	top: "res4c_branch2a"
	name: "C4_3: h4a_3"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4c_branch2a"
	top: "res4c_branch2a"
	name: "C4_3: bn4a_3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res4c_branch2a"
	top: "res4c_branch2a"
	name: "C4_3: relu4a_3"
	type: "ReLU"
}

layer {
	bottom: "res4c_branch2a"
	top: "res4c_branch2b"
	name: "C4_3: h4b_3"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4c_branch2b"
	top: "res4c_branch2b"
	name: "C4_3: bn4b_3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4c_branch2b"
	top: "res4c_branch2b"
	name: "C4_3: relu4b_3"
	type: "ReLU"
}

layer {
	bottom: "res4c_branch2b"
	top: "res4c_branch2c"
	name: "C4_3: h4c_3"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4c_branch2c"
	top: "res4c_branch2c"
	name: "C4_3: bn4c_3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res4b"
	bottom: "res4c_branch2c"
	top: "res4c"
	name: "C4_3: add4_3"
	type: "Eltwise"
}

layer {
	bottom: "res4c"
	top: "res4c"
	name: "C4_3: relu4_3"
	type: "ReLU"
}

layer {
	bottom: "res4c"
	top: "res4d_branch2a"
	name: "C4_4: h4a_4"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4d_branch2a"
	top: "res4d_branch2a"
	name: "C4_4: bn4a_4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res4d_branch2a"
	top: "res4d_branch2a"
	name: "C4_4: relu4a_4"
	type: "ReLU"
}

layer {
	bottom: "res4d_branch2a"
	top: "res4d_branch2b"
	name: "C4_4: h4b_4"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4d_branch2b"
	top: "res4d_branch2b"
	name: "C4_4: bn4b_4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4d_branch2b"
	top: "res4d_branch2b"
	name: "C4_4: relu4b_4"
	type: "ReLU"
}

layer {
	bottom: "res4d_branch2b"
	top: "res4d_branch2c"
	name: "C4_4: h4c_4"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4d_branch2c"
	top: "res4d_branch2c"
	name: "C4_4: bn4c_4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4c"
	bottom: "res4d_branch2c"
	top: "res4d"
	name: "C4_4: add4_4"
	type: "Eltwise"
}

layer {
	bottom: "res4d"
	top: "res4d"
	name: "C4_4: relu4_4"
	type: "ReLU"
}

layer {
	bottom: "res4d"
	top: "res4e_branch2a"
	name: "C4_5: h4a_5"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4e_branch2a"
	top: "res4e_branch2a"
	name: "C4_5: bn4a_5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4e_branch2a"
	top: "res4e_branch2a"
	name: "C4_5: relu4a_5"
	type: "ReLU"
}

layer {
	bottom: "res4e_branch2a"
	top: "res4e_branch2b"
	name: "C4_5: h4b_5"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4e_branch2b"
	top: "res4e_branch2b"
	name: "C4_5: bn4b_5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4e_branch2b"
	top: "res4e_branch2b"
	name: "C4_5: relu4b_5"
	type: "ReLU"
}

layer {
	bottom: "res4e_branch2b"
	top: "res4e_branch2c"
	name: "C4_5: h4c_5"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4e_branch2c"
	top: "res4e_branch2c"
	name: "C4_5: bn4c_5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4d"
	bottom: "res4e_branch2c"
	top: "res4e"
	name: "C4_5: add4_5"
	type: "Eltwise"
}

layer {
	bottom: "res4e"
	top: "res4e"
	name: "C4_5: relu4_5"
	type: "ReLU"
}

layer {
	bottom: "res4e"
	top: "res4f_branch2a"
	name: "C4_6: h4a_6"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4f_branch2a"
	top: "res4f_branch2a"
	name: "C4_6: bn4a_6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4f_branch2a"
	top: "res4f_branch2a"
	name: "C4_6: relu4a_6"
	type: "ReLU"
}

layer {
	bottom: "res4f_branch2a"
	top: "res4f_branch2b"
	name: "C4_6: h4b_6"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4f_branch2b"
	top: "res4f_branch2b"
	name: "C4_6: bn4b_6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4f_branch2b"
	top: "res4f_branch2b"
	name: "C4_6: relu4b_6"
	type: "ReLU"
}

layer {
	bottom: "res4f_branch2b"
	top: "res4f_branch2c"
	name: "C4_6: h4c_6"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4f_branch2c"
	top: "res4f_branch2c"
	name: "C4_6: bn4c_6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4e"
	bottom: "res4f_branch2c"
	top: "res4f"
	name: "C4_6: add4_6"
	type: "Eltwise"
}

layer {
	bottom: "res4f"
	top: "res4f"
	name: "C4_6: relu4_6"
	type: "ReLU"
}

layer {
	bottom: "res4f"
	top: "res5a_branch1"
	name: "C5_1: h_proj5"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch1"
	top: "res5a_branch1"
	name: "C5_1: bn_proj5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res4f"
	top: "res5a_branch2a"
	name: "C5_1: h5a_1"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2a"
	name: "C5_1: bn5a_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2a"
	name: "C5_1: relu5a_1"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2b"
	name: "C5_1: h5b_1"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2b"
	name: "C5_1: bn5b_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2b"
	name: "C5_1: relu5b_1"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2c"
	name: "C5_1: h5c_1"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2c"
	top: "res5a_branch2c"
	name: "C5_1: bn5c_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res5a_branch1"
	bottom: "res5a_branch2c"
	top: "res5a"
	name: "C5_1: add5_1"
	type: "Eltwise"
}

layer {
	bottom: "res5a"
	top: "res5a"
	name: "C5_1: relu5_1"
	type: "ReLU"
}

layer {
	bottom: "res5a"
	top: "res5b_branch2a"
	name: "C5_2: h5a_2"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2a"
	name: "C5_2: bn5a_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2a"
	name: "C5_2: relu5a_2"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2b"
	name: "C5_2: h5b_2"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2b"
	name: "C5_2: bn5b_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2b"
	name: "C5_2: relu5b_2"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2c"
	name: "C5_2: h5c_2"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2c"
	top: "res5b_branch2c"
	name: "C5_2: bn5c_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res5a"
	bottom: "res5b_branch2c"
	top: "res5b"
	name: "C5_2: add5_2"
	type: "Eltwise"
}

layer {
	bottom: "res5b"
	top: "res5b"
	name: "C5_2: relu5_2"
	type: "ReLU"
}

layer {
	bottom: "res5b"
	top: "res5c_branch2a"
	name: "C5_3: h5a_3"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2a"
	name: "C5_3: bn5a_3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2a"
	name: "C5_3: relu5a_3"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2b"
	name: "C5_3: h5b_3"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2b"
	name: "C5_3: bn5b_3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}



layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2b"
	name: "C5_3: relu5b_3"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2c"
	name: "C5_3: h5c_3"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2c"
	top: "res5c_branch2c"
	name: "C5_3: bn5c_3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}


layer {
	bottom: "res5b"
	bottom: "res5c_branch2c"
	top: "res5c"
	name: "C5_3: add5_3"
	type: "Eltwise"
}

layer {
	bottom: "res5c"
	top: "res5c"
	name: "C5_3: relu5_3"
	type: "ReLU"
}

layer {
	bottom: "res5c"
	top: "pool5"
	name: "FC: pool5"
	type: "Pooling"
	pooling_param {
		kernel_size: 7
		stride: 1
		pool: AVE
	}
}

layer {
	bottom: "pool5"
	top: "fc1000"
	name: "FC: fc1000"
	type: "InnerProduct"
	inner_product_param {
		num_output: 1000
	}
}

layer {
	bottom: "fc1000"
	top: "prob"
	name: "prob"
	type: "Softmax"
}
